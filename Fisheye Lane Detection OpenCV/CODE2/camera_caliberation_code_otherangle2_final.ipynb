{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb96dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required modules\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde2e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read and Show the input image \n",
    "original_image=cv2.imread('otherangle2.jpeg')\n",
    "cv2.imshow('Original_image',original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8ed4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For highlighting a specific region og the image and supressing the other regions\n",
    "def region_of_interest(image):\n",
    "    img_height = image.shape[0]\n",
    "    img_width = image.shape[1]\n",
    "    # Define the vertices of a polygon that represents the region of interest (ROI).\n",
    "    # Here we highlight the BOTTOM part of the image and maskout the remaining part of the image\n",
    "    vertices = np.array([\n",
    "        [(0,img_height),\n",
    "         (0, img_height*0.3),\n",
    "         (img_width, img_height*0.3),\n",
    "         (img_width, img_height)]\n",
    "    ], dtype=np.int32)\n",
    "    \n",
    "    # Create an empty mask image with the same dimensions as the input image.\n",
    "    mask= np.zeros_like(image)\n",
    "    # Fill the region defined by the polygon with a white color (255) to create the mask.\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    # Bitwise AND between the input image and the mask\n",
    "    # This operation retains the pixel values in the ROI (defined by the mask) and sets the rest to zero.\n",
    "    highlighted_image = cv2.bitwise_and(image, mask)\n",
    "    \n",
    "    return highlighted_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63644b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting edges from the input image\n",
    "\n",
    "def canny(image):\n",
    "    # Convert to grayscale as only image intensity needed for gradients\n",
    "    gray_image= cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # 5x5 gaussian blur to reduce noise \n",
    "    blur = cv2.GaussianBlur(gray_image, (5,5), 0)\n",
    "    \n",
    "    # Canny edge detector with minVal of 50 and maxVal of 150\n",
    "    edges = cv2.Canny(blur, 70, 180)\n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2bd991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For correcting the distortions present in the fish eye input image\n",
    "def distortion_correction(image):\n",
    "    #Camera orientation and Field Of View Parameters in degrees\n",
    "    cameraHeading= 90.0 #cameras horizontal direction or rotation\n",
    "    cameraPitch= 90.0 #cameras vertical direction or rotation\n",
    "    cameraFOV= 90.0 #cameras field of view in degrees\n",
    "    #dimensions of input image\n",
    "    img_width, img_height = original_image.shape[1],original_image.shape[0]\n",
    "    print(f\"Input Image width = {img_width}\")\n",
    "    print(f\"Input Image height = {img_height}\")\n",
    "\n",
    "    #dimensions of destination image that will hold the corrected image\n",
    "    outimg_width= img_width-20\n",
    "    outimg_height= img_height-20\n",
    "\n",
    "    #Initializing camera parameters\n",
    "    DEG2RAD= math.pi/180.0 #converting degree to radians\n",
    "\n",
    "    #Calculating the required camera parameters\n",
    "    vertical_map= img_height / math.pi # for mapping cameras vertical angles\n",
    "    horizontal_map= 0.5*img_width / math.pi #for mapping the entire range of horizontal angles\n",
    "    upFactor= 2.0 * math.tan(cameraFOV* DEG2RAD / 2.0) #factor to control amount of vertical stretching or compression\n",
    "    rightFactor= 1.33 * upFactor #factor to achieve desired horizontal correction\n",
    "\n",
    "    #calculating direction vector of camera\n",
    "    X_cameraDir= math.sin(cameraPitch * DEG2RAD) * math.sin(cameraHeading * DEG2RAD)\n",
    "    Y_cameraDir= math.cos(cameraPitch * DEG2RAD)\n",
    "    Z_cameraDir= math.sin(cameraPitch * DEG2RAD) * math.cos(cameraHeading * DEG2RAD)\n",
    "\n",
    "    #calculating up vector of camera using upFactor\n",
    "    X_cameraUp= upFactor * math.sin((cameraPitch-90.0)*DEG2RAD)* math.sin(cameraHeading* DEG2RAD)\n",
    "    Y_cameraUp= upFactor * math.cos((cameraPitch-90.0)*DEG2RAD)\n",
    "    Z_cameraUp= upFactor * math.sin((cameraPitch-90.0)*DEG2RAD)* math.cos(cameraHeading* DEG2RAD)\n",
    "\n",
    "    #calculating right vector of camera using rightFactor\n",
    "    X_cameraRight= rightFactor * math.sin((cameraHeading-90.0)*DEG2RAD)\n",
    "    Y_cameraRight= 0.0\n",
    "    Z_cameraRight= rightFactor * math.cos((cameraHeading-90.0)*DEG2RAD)\n",
    "\n",
    "    #calculating origin of the camera plane\n",
    "    X_cameraPlaneOrigin= X_cameraDir + 0.5 * X_cameraUp - 0.5 * X_cameraRight\n",
    "    Y_cameraPlaneOrigin= Y_cameraDir + 0.5 * Y_cameraUp - 0.5 * Y_cameraRight\n",
    "    Z_cameraPlaneOrigin= Z_cameraDir + 0.5 * Z_cameraUp - 0.5 * Z_cameraRight\n",
    "    FOV= math.pi * 130.0 / 180.0\n",
    "    \n",
    "    #Creating an empty destination image to hold the corrected image\n",
    "    size= outimg_height, outimg_width, 3\n",
    "    outimg= np.zeros(size, dtype=float)\n",
    "    \n",
    "    #for accessing each individual pixel in output image space\n",
    "    for i in range(1, outimg_height):\n",
    "        for j in range(1, outimg_width):\n",
    "            #fractional position of current pixel in output image space\n",
    "            fx= float(j) / float(outimg_width)\n",
    "            fy= float(i) / float(outimg_height)\n",
    "            \n",
    "            #computing the 3D ray direction for the current pixel\n",
    "            X_ray= X_cameraPlaneOrigin + fx* X_cameraRight - fy* X_cameraUp\n",
    "            Y_ray= Y_cameraPlaneOrigin + fx* Y_cameraRight - fy* Y_cameraUp\n",
    "            Z_ray= Z_cameraPlaneOrigin + fx* Z_cameraRight - fy* Z_cameraUp\n",
    "            #Calculating magnitutde of the ray direction\n",
    "            normRay = math.sqrt(Y_ray*Y_ray + Z_ray*Z_ray)\n",
    "            \n",
    "            #Calculating fisheye angle and radius\n",
    "            azimuthal_angle = math.atan2(Z_ray, Y_ray) #angle measured in xy plan from x axis towards y axis\n",
    "            polar_angle = math.atan2(normRay, X_ray) #angle measured from z axis towards xy plane\n",
    "            # represents the radial distance in the fisheye image from the image center to the current pixel\n",
    "            # value of r indicates how far a pixel should be from the image center to correct the distortion\n",
    "            #controls how much each pixel should be moved from its distorted position to its corrected position\n",
    "            radius= img_height * polar_angle / FOV \n",
    "            \n",
    "            #Mapping to pixels between distorted and corrected image\n",
    "            \n",
    "            #represents the x-coordinate (column) in the corrected fisheye image where the current pixel from the original fisheye image should be placed\n",
    "            azimuthal_map = math.floor(0.5*img_width + radius * math.sin(azimuthal_angle))\n",
    "            #represents the y-coordinate (row) in the corrected fisheye image where the current pixel from the original fisheye image should be placed\n",
    "            polar_map = math.floor(0.5*img_height - radius*math.cos(azimuthal_angle))\n",
    "            outimg_offset = (i*outimg_width + j) #calculates an index corresponding to the position of the pixel in the corrected image. Used for accessing and set pixel values in the corrected image\n",
    "            img_offset = (polar_map * img_width + azimuthal_map) #calculates index corresponding to the position of the pixel in the distorted fisheye image\n",
    "            row = max(min(int(polar_map),img_height-1),1) #represents row_index\n",
    "            #bounded by 1 to to avoid negative indices and img_height ensures that the indices stay within image bounds\n",
    "            col = max(min(int(azimuthal_map),img_width-1),1) #represents co_index\n",
    "            \n",
    "            #Incorporating colour values from input image to output image by obtaining corrected colour values for current pixels via INTERPOLATION\n",
    "            outimg[i,j,0]=image[row,col,0]/255.0 #divided by 255.0 to scale the values within an range of [0,1]\n",
    "            outimg[i,j,1]=image[row,col,1]/255.0\n",
    "            outimg[i,j,2]=image[row,col,2]/255.0\n",
    "            \n",
    "    return outimg * 255\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56684806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Image width = 320\n",
      "Input Image height = 158\n",
      "img_height= 138\n",
      "image_width = 300\n"
     ]
    }
   ],
   "source": [
    "#Displaying Input Image\n",
    "cv2.imshow('Input Image',original_image)\n",
    "\n",
    "#Correcting distorted image\n",
    "corrected_image=distortion_correction(original_image)\n",
    "corrected_image = corrected_image.astype(np.uint8)\n",
    "height,width=corrected_image.shape[0],corrected_image.shape[1]\n",
    "print(f'img_height= {height}')\n",
    "print(f'image_width = {width}')\n",
    "\n",
    "#Displaying Corrected Image\n",
    "cv2.imshow(\"corrected fisheyee image\",corrected_image)\n",
    "cv2.imwrite('corrected fisheyee otherangle2.jpg',corrected_image)\n",
    "\n",
    "#Detecting and Displaying edges\n",
    "canny_edges = canny(corrected_image)\n",
    "cv2.imshow('canny edges',canny_edges)\n",
    "cv2.imwrite('canny edges otherangle2.jpg',canny_edges)\n",
    "\n",
    "#Highlighting only a specific region of image\n",
    "masked_image=region_of_interest(canny_edges)\n",
    "cv2.imshow('canny edges after applying mask',masked_image)\n",
    "cv2.imwrite('roi mask otherangle2.jpg',masked_image)\n",
    "\n",
    "#Performin Hough lines to detect the lanes\n",
    "lines = cv2.HoughLinesP(\n",
    "    masked_image,\n",
    "    rho=2,\n",
    "    theta=np.pi / 180,\n",
    "    threshold=80,\n",
    "    lines=np.array([]),\n",
    "    minLineLength=80,\n",
    "    maxLineGap=5\n",
    ")\n",
    "\n",
    "#Drawing the detected lanes onto the image\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2=line[0]\n",
    "    cv2.line(corrected_image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "# Display the corrected image with lane detection\n",
    "cv2.imshow(\"Lane Detection\", corrected_image)\n",
    "cv2.imwrite('lane_detection_otherangle2.jpg',corrected_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
